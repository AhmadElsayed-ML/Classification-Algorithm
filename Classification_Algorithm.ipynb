{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyzcKBsEn/erpAJJu0wsgE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4gEHoFCch6H"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from __future__  import absolute_import, division, print_function, unicode_literals"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetttalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    'iris_train.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    'iris_trin.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "\n",
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "\n",
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "  #Convert the inputs to a dataset\n",
        "  dataset= tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "  #shuffle and repeat if you are in training mode\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "  return dataset.batch(batch_size)\n",
        "\n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "#Creating the Model\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns = my_feature_columns,\n",
        "    hidden_units= [30, 10],\n",
        "    n_classes=3)\n",
        "#Training the model\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training = True),\n",
        "    steps= 5000 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd3Xe8fKZnSt",
        "outputId": "278c3f01-960b-4af2-c176-b261de7e82b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpz4yew1tg\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7cf5a84e9330>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating our Ai Model\n",
        "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n' .format(**eval_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhoTqy47XxIn",
        "outputId": "2fdbef46-fe9f-40a5-fa6d-444c7d51da13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set accuracy: 0.967\n",
            "\n"
          ]
        }
      ]
    }
  ]
}